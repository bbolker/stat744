---
title: "INLA package for R"
author: "Taddele, Tian, Regina"
date:  "`r format(Sys.time(), '%H:%M %d %B %Y')`"
output: html_document
---

### Implementing INLA

The following are required to perform INLA  
a) The GMRFLib-library  
b) The INLA package for `R`

Downloading, installing and loading the INLA package

```{r loadpackage, echo=FALSE}
#install.packages("sp")   #classes and methods for spatial data 
install.packages("INLA", repos="http://www.math.ntnu.no/inla/R/stable")
library("INLA")
#?inla   #opens up the help file for all functions
```

Model Specification in the INLA package

Assume the following model:
$$
\begin{split}
y & \sim \pi(\eta|\lambda)\\
\eta & = g(\lambda) = \beta_{0} + \beta_{1}x_1 + \beta_{2}x_2 + f(x_3)
\end{split}
$$
where
$x_{1}, x_{2}$ are covariates with linear effect <br />
$\beta_{i}\sim N(0,\tau_{1}^{-1})$ <br />
$x_3$ can be spatial effect, random effect, etc <br />
$f_{1},f_{2},... \sim N(0,Q_{f}^{-1}(\tau_2))$

The model is specified in R through a formaula, similar to the one used in the glm routine:

```{r formula, echo=FALSE}
formula <- y ~x1 + x2 + f(x3)
```

The $f()$ function is used to specify non-linear effects in the model.

Examples of the implemented model are:

* `iid1: random effects
* `rw1` `rw2` `arl`: smooth effect of covariates or time effect
* `seasonal`: seasonal effect
* `besag`: spatial effect (CAR model)
* `generic`: user defined precision matrix

Main functions of the INLA package

- *f()*: helps define non linear effects in the model specification
- *inla()*: performs bayesian analysis of additive models
- *surv.inla()*: performs a bayesian analysis of some survival models
- additional functions of the INLA package
     i. *summary()*: produces a summary of the main results from a fitted model
    ii. *plot()*: produces some plot from the fitted model


Some examples of usage of the INLA package

- mixed effect model
- model with time series component
- model with spatial component
- model with space-varying regression coefficients
- model for survival data


### Examples
The following examples are mearnt to give an overview of the range of application of the INLA methodology

## Example 1: Simulating observations and states from a first order DLM (Toy Example)

The observational and the system equations respectively of the model is given as:
		$$
		\begin{split}
		y_{t} & =x_{t}+v_{t},  \ \ \  v_{t}\sim N(0,V), \ \ \   t=1,...,n \\
		 x_{t} & =x_{t-1}+w_{t},  \ \ \  w_{t}\sim N(0,W), \ \ \   t=2,...,n
		 \end{split}
		 $$
		 
Generic approach consists in equating to zero the system equation
		 $$
		 0=x_{t}-x_{t-1}+w_{t},  \ \ \  w_{t}\sim N(0,W), \ \ \   t=2,...,n		 
    $$
		 
```{r matrix_toy}
set.seed(123456)

W = 0.5
V = 1.0
n = 100
x0 = 0.00
w  = rnorm(n,0,sqrt(W))
v  = rnorm(n,0,sqrt(V))
x  = y = rep(0,n)                # a place holder for the x and y vector times
x[1] = x0   + w[1]               # system equations (state/latent parameters)
y[1] = x[1] + v[1]               # observational equations
for (t in 2:n){
  x[t] = x[t-1] + w[t]
  y[t] = x[t]   + v[t]
}
m = n-1

# building the augmented model
Y <- matrix(NA, n+m, 2)         # matrix for storing the actual and fake observations
Y[1:n,     1] <- y              # actual observations are stored in the first column
Y[1:m + n, 2] <- 0              # faked observations (assuming zero values) are in the second column
```

Defining the indices to be used by the INLA library
weights w1 and w2 are needed as x_{t-1} and w_t terms are negative in Eq. (5)
```{r indices_toy}
i  <- c(1:n, 2:n)              # indices for  the states x_t
j  <- c(rep(NA,n), 2:n -1)     # indices for x_{t-1}
w1 <- c(rep(NA,n), rep(-1,m))  # weights for x_{t-1}
l  <- c(rep(NA,n), 2:n)        # indices for the perturbation terms w_t
w2 <- c(rep(NA,n), rep(-1,m))  # weights for w_t
```


## Formulating the model

The states, $x_t$, (indexed by `i`) follow a Gaussian distribution with a fixed and low log-precision (-10). 
The $x_{t-1}$ terms (indexed by `j`) are modeled as a copy of the $x_t$ terms. 
The perturbations, $w_t$, (indexed by `l`) follow a Gaussian distribution with unknown log-precision.
```{r model_toy}
# formulation with default hyperprior
formula1 <- Y ~ f(i, model="iid", initial=-10, fixed=T) +
  f(j, w1, copy="i") +
  f(l, w2, model ="iid") -1

# formulation with informative hyperprior
formula2 <- Y ~ f(i, model="iid", initial=-10, fixed=TRUE) + 
                f(j, w1, copy="i") + 
                f(l, w2, model="iid", param=c(4, 1.2)) -1

# formulation with vague hyperprior
formula3 <- Y ~ f(i, model="iid", initial=-10, fixed=TRUE) + 
  f(j, w1, copy="i") + 
  f(l, w2, model="iid", param=c(0.01, 0.003)) -1
```


Fitting the model

Two different Gaussian likelihoods are defined (for the actual and faked observations) in the family statement. 
The list in "control.family" statement defines the parameters for the log-precisions of the actual and faked observations, respectively. Here, default values are assumed in the first case, whereas a high and fixed value (10) is defined for the log-precision in the second case
```{r inlamodel_toy}
# default prior
r1 <- inla(formula1, data = data.frame(i,j,w1,w2,l),
           family = rep("gaussian", 2), 
           control.family = list(list(), list(initial=10, fixed=T)),
           control.predictor=list(compute=TRUE))

# informative prior
r2 <- inla(formula2, data = data.frame(i,j,w1,w2,l),
           family = rep("gaussian", 2), 
           control.family = list(list(param=c(4,2)), list(initial=10, fixed=T)),
           control.predictor=list(compute=TRUE))

# vague prior
r3 <- inla(formula3, data = data.frame(i,j,w1,w2,l),
           family = rep("gaussian", 2), 
           control.family = list(list(param=c(0.01, 0.005)), list(initial=10, fixed=T)),
           control.predictor=list(compute=TRUE))

# elapsed time (seconds)
r1$cpu.used
r2$cpu.used
r3$cpu.used

# summary() function to inspect our results
summary(r1)
#summary(r2)
#summary(r3)

#names() function to see the list of variable names produced in the model
#names(r1)
```


Plotting the results for the simulated and the 
```{r plot_toy}
# graph for observations (y)
#par(mfrow=c(1,1), mar=c(5,6.5,2,1), mgp=c(4,1,0),cex.axis=2,cex.main=2,cex.lab=3)
rang <- range(r1$summary.fitted.values[1:n, 3:5], y)
plot(r1$summary.fitted.values[1:n,1], type="l", 
     ylim=rang, col="red", xlim=c(1,n),ylab=expression(y[t]),xlab="time",lwd=2)
lines(r1$summary.fitted.values[1:n,3], col="blue", lty=3,lwd=2)
lines(r1$summary.fitted.values[1:n,5], col="blue", lty=3,lwd=2)
lines(y[1:n],lwd=2)
legend("topright", legend=c("simulated y_t","posterior mean","95% CI"), col=c("black", "red","blue"),lty=c(1,1,2),lwd=c(2,2,2),bty="n",cex=0.7)
#title("a toy example")

# graph for states (x)
#par(mfrow=c(1,1), mar=c(5,6.5,2,1), mgp=c(4,1,0),cex.axis=2,cex.main=2,cex.lab=3)
rang <- range(r1$summary.random[[1]][1:n, 4:6], x)
plot(r1$summary.random[[1]][1:n,2], type="l", 
     ylim=rang, col="red", xlim=c(1,n),ylab=expression(x[t]),xlab="time",lwd=2)
lines(r1$summary.random[[1]][1:n,4], col="blue", lty=3,lwd=2)
lines(r1$summary.random[[1]][1:n,6], col="blue", lty=3,lwd=2)
lines(x[1:n],lwd=2)
legend("topright", legend=c("simulated X_t","posterior mean","95% CI"), col=c("black", "red","blue"),lty=c(1,1,2),lwd=c(2,2,2),bty="n",cex=0.7)
#title("a toy example")
```


```{r hyperparameter_toy}
# summary of posterior hyperparameters
# -------------------------------------
r1$summary.hyperpar
r2$summary.hyperpar
r3$summary.hyperpar
```


Plotting the results for posterior marginal of the hyperparameters
```{r posteriorhyper_toy}
# marginal posterior densities for precision parameters
# -----------------------------------------------------
par(mfrow=c(1,2))
#par(mfrow=c(1,1), mar=c(5,6.5,2,1), mgp=c(4,1,0),cex.axis=2,cex.main=2,cex.lab=3)
rang=range(r1$marginals.hyperpar[[1]][,2],r2$marginals.hyperpar[[1]][,2],r3$marginals.hyperpar[[1]][,2])
plot(r1$marginals.hyperpar[[1]], type="l", lwd=2,lty=1, xlab=expression(V^-1), main="precision for Gaussian observations", ylab="density",xlim=c(0,8),ylim=rang)  # precision of V
lines(r2$marginals.hyperpar[[1]],lwd=2,lty=2)
lines(r3$marginals.hyperpar[[1]],lwd=2,lty=3)
abline(v=1/V,col=2, lwd=2)
legend("topright",4,0.8, legend=c("with default prior","with informative prior","with vague prior"), lty=c(1,2,3),lwd=c(2,2,2),bty="n",cex=0.7)
#par(mfrow=c(1,1), mar=c(5,6.5,2,1), mgp=c(4,1,0),cex.axis=2,cex.main=2,cex.lab=3)
rang=range(r1$marginals.hyperpar[[2]][,2],r2$marginals.hyperpar[[2]][,2],r3$marginals.hyperpar[[2]][,2])
plot(r1$marginals.hyperpar[[2]], type="l", lwd=2, xlab=expression(W^-1), main=expression(paste("precision for",~ w[t])), ylab="density",xlim=c(0,10),ylim=rang)  # precision of W
lines(r2$marginals.hyperpar[[2]],lwd=2,lty=2)
lines(r3$marginals.hyperpar[[2]],lwd=2,lty=3)
abline(v=1/W,col=2, lwd=2)
```


## Example 2: A GLMM with over-dispersion
This is an example of GLMM with binomial likelihood where the random 
effects are used to model within group extra variation.
The data concern the proportion of seeds that germinated on each of $m = 21$ plates arranged in
a 2x2 factorial design with respect to seed variety and type of root extract.
The model is given as $y_i|\eta_i \sim Binomial(n_i,p_i)$ where $y_i$ is the number of 
germinating seeds(vn:r), $n_i$ the total number of seeds (vn: n) and $p_i=logit^{-1}\eta_i$
is the unkwon probability of germinating, $i=1,...,m$. The fitted model is:
$\eta_i=\beta_0 + \beta_1x_{1i}+\beta_2x_{2i}+\beta_3x_{1i}x_{2i}+f(u_i)$

Specifying our model 
```{r model_seeds}
formula = r ~ x1*x2 + f(plate, model="iid", param=c(1,0.001))
```

Running our model in INLA
```{r inlamodel_seeds}
data(Seeds)      # loading the Seed data into R
head(Seeds,3)    # to view the first three rows of the Seed data
mod.seeds = inla(formula, data=Seeds, family="binomial",Ntrials=n)
```
There is no need to specify the parameters for our prior distribution since we are using the default 
Gamma prior with $a=1$ and $b=0.001$.

Calling the $summary()$ function to inspect our reseults
```{r summary_seeds}
#options(digits=9)
summary(mod.seeds,digits=9)
```

Assume we are interested in the posterior mean and standard deviation of the variance parameter
$\sigma_{\mu}^2=1/\tau_{\mu}$, this can be done by selecting the appropriate posterior marginal
from the *inla()* function: 
```{r variancepar_seeds}
#names(mod.seeds) # can be used to view the various outputs produced by the inla() function
prec.marg=mod.seeds$marginals.hyperpar$`Precision for plate` #produces the individual precision values
#m1=inla.expectation(function(x) 1/x, prec.marg)     #not working 
m1=mean(1/prec.marg[,1])
#m2=inla.expectation(function(x) (1/x)^2, prec.marg) #not working
m2=mean((1/prec.marg[,1])^2)
sd=sqrt(m2-m1^2)
print(c(mean=m1, sd=sd))
```

One can sample from the posterior densities.
A sample of size 1000 from the posterior $\tilde{\pi}(\beta_1|y)$ can be obtained as:
```{r sampling_seeds}
dens = mod.seeds$marginals.fixed$x1 
sample = inla.rmarginal(1000,dens)
```



### Example 3: Childhood undernutrition in Zambia: Spatial analysis

Three different spatial models are considered to analyze the Zambia data. 
The authors study childhood undernutrition in 57 regions of Zambia. A total of $n_d = 4847$ observation are included in the data set. Stunting for child $i = 1,...,n_d$ is determined using a $Z$ score defined as:
$$
Z_i = \dfrac{AI_i - MAI}{\sigma}
$$
where: $AI$ is the child's anthropometric indicator, $MAI$ is the median of
the reference population and $\sigma$ refers to the deviation of the standard population
Covariates include  age of the child ($age_i$),the body mass index of the child's mother ($bmi_i$), the district the child lives in ($s_i$). $Z_i$ (vn: hazstd) is assumed to be conditionally independent Gaussian
random variables with unknown mean $\eta_i$ and unknown precision $\tau_z$

Model 1: Assumption: all covariates have linear effect
$$
\eta_i=\mu + {\bf z}_i^T \beta + f_s(s_i) + f_u(s_i)
$$

Model 2: Assumption: age of child is smooth but not linear
$$
\eta_i=\mu + {\bf z}_i^T \beta + f_1(age_i)+ f_s(s_i) + f_u(s_i)
$$

Model 3: Assumption: Effect of bmi is linear but possess different slope for different regions
$$
\eta_i=\mu + {\bf z}_i^T \beta + f_1(age_i)+ bmi_i f_2(s_i)
$$

```{r data_zambia}
##load the data set
data(Zambia)
##load map
g = system.file("demodata/zambia.graph", package="INLA")
# add one column for the unstructured spatial effect
Zambia$distr.unstruct  =  Zambia$district

## define formula for the model
formula= hazstd ~  edu1 + edu2 + tpr + sex + bmi + agc +
  f(district, model="besag", graph = g) +
  f(distr.unstruct, model="iid") 

# model
mod  =  inla(formula, data = Zambia, family = "gaussian",
              control.compute = list(dic = TRUE, cpo=TRUE))
summary(mod)
plot(mod)
```



```{r formaula_zambia}
##MOD1
formula.mod1 = hazstd ~  agc + edu1 + edu2 + tpr + sex + bmi +
  f(district, model="besag", graph = g, param = c(1,0.01)) +
  f(distr.unstruct, model="iid", param = c(1,0.01)) 
  

##MOD2
formula.mod2 = hazstd ~ edu1 + edu2 + tpr + sex + bmi +
  f(agc, model = "rw2") +
  f(district, model="besag", graph = g, param = c(1,0.01)) +
  f(distr.unstruct, model="iid", param = c(1,0.01)) 
  

##MOD3
formula.mod3 = hazstd ~ edu1 + edu2 + tpr + sex +
  f(agc, model = "rw2") +
  f(district, bmi, model = "besag", graph = g, param = c(1,0.01), constr = FALSE) 
  
```



```{r inla_zambia}
##run the three models
mod1  =  inla(formula.mod1, data = Zambia, control.family = list(initial = 1),
              control.inla = list(h=1e-4),
              control.compute = list(dic = TRUE, cpo=TRUE),
              verbose = F)

mod2  =  inla(formula.mod2, data = Zambia, control.family = list(initial = 1),
              control.inla = list(h = 1e-4),
              control.compute = list(dic = TRUE,cpo=TRUE),
              verbose = F)

mod3  =  inla(formula.mod3,data = Zambia, control.family = list(initial = 1),
              control.inla = list(h = 1e-4),
              control.compute = list(dic = TRUE,cpo=TRUE),
              verbose = F)
plot(mod1)
plot(mod2)
plot(mod3)

a<-summary(mod1)
b<-summary(mod2)
c<-summary(mod3)
##compute the log-score
log.score1 = -mean(log(mod1$cpo$cpo))
log.score2 = -mean(log(mod2$cpo$cpo))
log.score3 = -mean(log(mod3$cpo$cpo))

##pit histogram
par(mfrow=c(3,1))
hist(mod1$cpo$pit,br=30)
hist(mod2$cpo$pit,br=30)
hist(mod3$cpo$pit,br=30)
```


```{r comp_zambia}
#comparison
#linear effect pamaeters in the three models for the Zambia data
a$fixed[,-7]#mod1
b$fixed[,-7]#mod2
c$fixed[,-7]#mod3

# list of the hyperparameters in the three models for the Zambia data
a$hyperpar#mod1
b$hyperpar#mod2
c$hyperpar#mod3


# list of the Expectected,standard deviation of the # of parameters in the three models for the Zambia data
compEn<-cbind(a$neffp,b$neffp,b$neffp)
colnames(compEn)=c("mod1","mod2","mod3")
#DIC, and log score
modelDIC<-c(a$dic$dic,b$dic$dic,c$dic$dic)
log.score = c(log.score1,log.score2,log.score3 )
compEn1<-rbind(compEn,modelDIC,log.score)
compEn1


# list of cpuused in the three models for the Zambia data
compcpu<-rbind(a$cpu.used,b$cpu.used,b$cpu.used)
rownames(compcpu)=c("mod1","mod2","mod3")
compcpu

# list of log marginal-likelihood in the three models for the Zambia data
compMlik<-cbind(a$mlik,b$mlik,b$mlik)
colnames(compMlik)=c("mod1","mod2","mod3")
compMlik
```


```{r plot_zambia}

#page12 Fig2.a Estiamted effect of age (posterior mean 
#together with 2.5% and 97.5% quantiles) useing MOD2
library(ggplot2)

mydata2 <- as.data.frame(mod2$summary.random$agc)

ggplot(mydata2) +   
  geom_line(aes(ID, `0.5quant`)) +   
  geom_line(aes(ID, `0.025quant`), linetype="dashed") +   
  geom_line(aes(ID, `0.975quant`), linetype="dashed") + 
ggtitle("Estiamted effect of age (posterior mean 
together with 2.5% and 97.5% quantiles) using MOD2")


#page12 Fig2.a Estiamted effect of age (posterior mean 
#together with 2.5% and 97.5% quantiles) useing MOD3

mydata3 <- as.data.frame(mod3$summary.random$agc)

ggplot(mydata3) +   
  geom_line(aes(ID, `0.5quant`)) +   
  geom_line(aes(ID, `0.025quant`), linetype="dashed") +   
  geom_line(aes(ID, `0.975quant`), linetype="dashed") + 
  ggtitle("Estimated effect of age (posterior mean 
together with 2.5% and 97.5% quantiles) using MOD3")
```



